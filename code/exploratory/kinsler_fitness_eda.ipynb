{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) 2023 Manuel Razo. This work is licensed under a [Creative Commons\n",
    "Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).\n",
    "All code contained herein is licensed under an [MIT\n",
    "license](https://opensource.org/licenses/MIT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load project package\n",
    "@load_pkg BayesFitUtils\n",
    "\n",
    "# Import project package\n",
    "import BayesFitUtils\n",
    "\n",
    "# Import package to handle DataFrames\n",
    "import DataFrames as DF\n",
    "import CSV\n",
    "import Tables\n",
    "\n",
    "# Import package to load chains\n",
    "import JLD2\n",
    "\n",
    "# Import package to handle MCMC chain objects\n",
    "import MCMCChains\n",
    "\n",
    "# Import basic statistical functions\n",
    "import StatsBase\n",
    "import Distributions\n",
    "\n",
    "# Import library to list files\n",
    "import Glob\n",
    "\n",
    "# Load CairoMakie for plotting\n",
    "using CairoMakie\n",
    "import ColorSchemes\n",
    "import Makie\n",
    "# Activate backend\n",
    "CairoMakie.activate!()\n",
    "\n",
    "# Set PBoC Plotting style\n",
    "BayesFitUtils.viz.pboc_makie!()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitness inference exploratory data analysis for Kinsler et al., 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore the output of the inferences done on the\n",
    "Kinsler et al., 2020 datasets.\n",
    "\n",
    "Let us begin by loading the inferences done exclusively on the neutral linages\n",
    "to infer the prior values for the full joint inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of files = 51\n"
     ]
    }
   ],
   "source": [
    "# Define directory\n",
    "out_dir = \"$(git_root())/code/processing/mcmc_kinsler_fitness/\" *\n",
    "          \"output/popmean_fitness\"\n",
    "\n",
    "# List files\n",
    "files = Glob.glob(\"$(out_dir)/kinsler*jld2\"[2:end], \"/\")\n",
    "\n",
    "println(\"# of files = $(length(files))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's loop through the files, load the chains, and fit parametric\n",
    "distributions to the relevant parameters to determine the value of the priors.\n",
    "To better organize all of this information, we will store the values on a tidy\n",
    "dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"kinsler_0.2MKClenv_R1rep_falsermT0_1000steps_04walkers.jld2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split(files[1], \"/\")[end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>8×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">s_mean</th><th style = \"text-align: left;\">s_std</th><th style = \"text-align: left;\">σ_mean</th><th style = \"text-align: left;\">σ_std</th><th style = \"text-align: left;\">env</th><th style = \"text-align: left;\">rep</th><th style = \"text-align: left;\">time</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">0.451544</td><td style = \"text-align: right;\">0.0448838</td><td style = \"text-align: right;\">-1.98867</td><td style = \"text-align: right;\">0.336591</td><td style = \"text-align: left;\">0.2MKCl</td><td style = \"text-align: left;\">R1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">0.400424</td><td style = \"text-align: right;\">0.0578217</td><td style = \"text-align: right;\">-1.70192</td><td style = \"text-align: right;\">0.2836</td><td style = \"text-align: left;\">0.2MKCl</td><td style = \"text-align: left;\">R1</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">0.429273</td><td style = \"text-align: right;\">0.072205</td><td style = \"text-align: right;\">-1.53064</td><td style = \"text-align: right;\">0.307813</td><td style = \"text-align: left;\">0.2MKCl</td><td style = \"text-align: left;\">R1</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">0.366196</td><td style = \"text-align: right;\">0.0835919</td><td style = \"text-align: right;\">-1.43045</td><td style = \"text-align: right;\">0.304358</td><td style = \"text-align: left;\">0.2MKCl</td><td style = \"text-align: left;\">R1</td><td style = \"text-align: right;\">4</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">0.390209</td><td style = \"text-align: right;\">0.0711818</td><td style = \"text-align: right;\">-1.54629</td><td style = \"text-align: right;\">0.286934</td><td style = \"text-align: left;\">0.2MNaCl</td><td style = \"text-align: left;\">R1</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">0.36445</td><td style = \"text-align: right;\">0.0548963</td><td style = \"text-align: right;\">-1.75539</td><td style = \"text-align: right;\">0.304978</td><td style = \"text-align: left;\">0.2MNaCl</td><td style = \"text-align: left;\">R1</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">0.534052</td><td style = \"text-align: right;\">0.0742311</td><td style = \"text-align: right;\">-1.48813</td><td style = \"text-align: right;\">0.308161</td><td style = \"text-align: left;\">0.2MNaCl</td><td style = \"text-align: left;\">R1</td><td style = \"text-align: right;\">3</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">0.32696</td><td style = \"text-align: right;\">0.0787879</td><td style = \"text-align: right;\">-1.47863</td><td style = \"text-align: right;\">0.333311</td><td style = \"text-align: left;\">0.2MNaCl</td><td style = \"text-align: left;\">R1</td><td style = \"text-align: right;\">4</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& s\\_mean & s\\_std & σ\\_mean & σ\\_std & env & rep & time\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & String & String & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.451544 & 0.0448838 & -1.98867 & 0.336591 & 0.2MKCl & R1 & 1 \\\\\n",
       "\t2 & 0.400424 & 0.0578217 & -1.70192 & 0.2836 & 0.2MKCl & R1 & 2 \\\\\n",
       "\t3 & 0.429273 & 0.072205 & -1.53064 & 0.307813 & 0.2MKCl & R1 & 3 \\\\\n",
       "\t4 & 0.366196 & 0.0835919 & -1.43045 & 0.304358 & 0.2MKCl & R1 & 4 \\\\\n",
       "\t5 & 0.390209 & 0.0711818 & -1.54629 & 0.286934 & 0.2MNaCl & R1 & 1 \\\\\n",
       "\t6 & 0.36445 & 0.0548963 & -1.75539 & 0.304978 & 0.2MNaCl & R1 & 2 \\\\\n",
       "\t7 & 0.534052 & 0.0742311 & -1.48813 & 0.308161 & 0.2MNaCl & R1 & 3 \\\\\n",
       "\t8 & 0.32696 & 0.0787879 & -1.47863 & 0.333311 & 0.2MNaCl & R1 & 4 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m8×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m s_mean   \u001b[0m\u001b[1m s_std     \u001b[0m\u001b[1m σ_mean   \u001b[0m\u001b[1m σ_std    \u001b[0m\u001b[1m env      \u001b[0m\u001b[1m rep    \u001b[0m\u001b[1m time  \u001b[0m\n",
       "     │\u001b[90m Float64  \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m String   \u001b[0m\u001b[90m String \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "─────┼──────────────────────────────────────────────────────────────────\n",
       "   1 │ 0.451544  0.0448838  -1.98867  0.336591  0.2MKCl   R1          1\n",
       "   2 │ 0.400424  0.0578217  -1.70192  0.2836    0.2MKCl   R1          2\n",
       "   3 │ 0.429273  0.072205   -1.53064  0.307813  0.2MKCl   R1          3\n",
       "   4 │ 0.366196  0.0835919  -1.43045  0.304358  0.2MKCl   R1          4\n",
       "   5 │ 0.390209  0.0711818  -1.54629  0.286934  0.2MNaCl  R1          1\n",
       "   6 │ 0.36445   0.0548963  -1.75539  0.304978  0.2MNaCl  R1          2\n",
       "   7 │ 0.534052  0.0742311  -1.48813  0.308161  0.2MNaCl  R1          3\n",
       "   8 │ 0.32696   0.0787879  -1.47863  0.333311  0.2MNaCl  R1          4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize dataframe to save distribution parameters\n",
    "df_popmean = DF.DataFrame()\n",
    "\n",
    "# Loop through files\n",
    "for f in files\n",
    "    # Split file name\n",
    "    f_split = split(split(f, \"/\")[end], \"_\")\n",
    "\n",
    "    # Extract file metadata\n",
    "    env = replace(f_split[2], \"env\" => \"\")\n",
    "    rep = replace(f_split[3], \"rep\" => \"\")\n",
    "\n",
    "    # Load chain into memory\n",
    "    chn = JLD2.load(f)[\"chain\"]\n",
    "\n",
    "    # Select variables for population mean fitness and associated variance\n",
    "    var_name = MCMCChains.namesingroup.(Ref(chn), [:s̲ₜ, :σ̲ₜ])\n",
    "\n",
    "    # Fit normal distributions to population mean fitness\n",
    "    pop_mean = Distributions.fit.(\n",
    "        Ref(Distributions.Normal), [vec(chn[x]) for x in var_name[1]]\n",
    "    )\n",
    "\n",
    "    # Fit lognormal distributions to associated error\n",
    "    pop_std = Distributions.fit.(\n",
    "        Ref(Distributions.LogNormal), [vec(chn[x]) for x in var_name[2]]\n",
    "    )\n",
    "\n",
    "    # Extract distribution parameters into matrix\n",
    "    df_param = DF.DataFrame(\n",
    "        hcat(\n",
    "            first.(Distributions.params.(pop_mean)),\n",
    "            last.(Distributions.params.(pop_mean)),\n",
    "            first.(Distributions.params.(pop_std)),\n",
    "            last.(Distributions.params.(pop_std))\n",
    "        ),\n",
    "        [\"s_mean\", \"s_std\", \"σ_mean\", \"σ_std\"]\n",
    "    )\n",
    "\n",
    "    # Add columns for time and metadata\n",
    "    DF.insertcols!(\n",
    "        df_param,\n",
    "        :env .=> env,\n",
    "        :rep .=> rep,\n",
    "        :time => axes(df_param, 1)\n",
    "    )\n",
    "\n",
    "    # Append to dataframe\n",
    "    DF.append!(df_popmean, df_param)\n",
    "end # for\n",
    "\n",
    "# Write dataframe into CSV file\n",
    "CSV.write(\"$(out_dir)/popmean_fitness_priors.csv\", df_popmean)\n",
    "\n",
    "first(df_popmean, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use these values to set the priors for the global joint inference.\n",
    "Specifically, we use the parameters for the population mean fitness values\n",
    "(`s_mean`, and `s_std`) to set the priors for the population mean fitness when\n",
    "performing the joint inference. The same for the parameters on the standard\n",
    "deviation of the likelihood function for the neutral lineages. Furthermore,\n",
    "we use these latter parameters also as the priors on the standard deviation of\n",
    "the likelihood function for the mutant lineages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat an equivalent analysis for the barcode frequencies. First, let's\n",
    "list the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of files = 51\n"
     ]
    }
   ],
   "source": [
    "# Define directory\n",
    "out_dir = \"$(git_root())/code/processing/mcmc_kinsler_fitness/\" *\n",
    "          \"output/bc_freq\"\n",
    "\n",
    "# List files\n",
    "files = Glob.glob(\"$(out_dir)/kinsler*jld2\"[2:end], \"/\")\n",
    "\n",
    "println(\"# of files = $(length(files))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's fit parametric distributions to the Poisson parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>8×6 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">λ_mean</th><th style = \"text-align: left;\">λ_std</th><th style = \"text-align: left;\">bc_mean</th><th style = \"text-align: left;\">bc_std</th><th style = \"text-align: left;\">env</th><th style = \"text-align: left;\">rep</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"String\" style = \"text-align: left;\">String</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">8.73987</td><td style = \"text-align: right;\">0.0110089</td><td style = \"text-align: right;\">6247.43</td><td style = \"text-align: right;\">68.7797</td><td style = \"text-align: left;\">0.2MKCl</td><td style = \"text-align: left;\">R1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">7.75991</td><td style = \"text-align: right;\">0.0219595</td><td style = \"text-align: right;\">2345.25</td><td style = \"text-align: right;\">51.5066</td><td style = \"text-align: left;\">0.2MKCl</td><td style = \"text-align: left;\">R1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">7.37042</td><td style = \"text-align: right;\">0.0254693</td><td style = \"text-align: right;\">1588.81</td><td style = \"text-align: right;\">40.4725</td><td style = \"text-align: left;\">0.2MKCl</td><td style = \"text-align: left;\">R1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">4.59857</td><td style = \"text-align: right;\">0.107446</td><td style = \"text-align: right;\">99.9174</td><td style = \"text-align: right;\">10.7668</td><td style = \"text-align: left;\">0.2MKCl</td><td style = \"text-align: left;\">R1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">4.92564</td><td style = \"text-align: right;\">0.0779711</td><td style = \"text-align: right;\">138.196</td><td style = \"text-align: right;\">10.7917</td><td style = \"text-align: left;\">0.2MKCl</td><td style = \"text-align: left;\">R1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">8.66376</td><td style = \"text-align: right;\">0.0130694</td><td style = \"text-align: right;\">5789.76</td><td style = \"text-align: right;\">75.6719</td><td style = \"text-align: left;\">0.2MKCl</td><td style = \"text-align: left;\">R1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">7.74126</td><td style = \"text-align: right;\">0.02048</td><td style = \"text-align: right;\">2301.86</td><td style = \"text-align: right;\">47.1469</td><td style = \"text-align: left;\">0.2MKCl</td><td style = \"text-align: left;\">R1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">7.34235</td><td style = \"text-align: right;\">0.0205986</td><td style = \"text-align: right;\">1544.66</td><td style = \"text-align: right;\">31.8211</td><td style = \"text-align: left;\">0.2MKCl</td><td style = \"text-align: left;\">R1</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& λ\\_mean & λ\\_std & bc\\_mean & bc\\_std & env & rep\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & String & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 8.73987 & 0.0110089 & 6247.43 & 68.7797 & 0.2MKCl & R1 \\\\\n",
       "\t2 & 7.75991 & 0.0219595 & 2345.25 & 51.5066 & 0.2MKCl & R1 \\\\\n",
       "\t3 & 7.37042 & 0.0254693 & 1588.81 & 40.4725 & 0.2MKCl & R1 \\\\\n",
       "\t4 & 4.59857 & 0.107446 & 99.9174 & 10.7668 & 0.2MKCl & R1 \\\\\n",
       "\t5 & 4.92564 & 0.0779711 & 138.196 & 10.7917 & 0.2MKCl & R1 \\\\\n",
       "\t6 & 8.66376 & 0.0130694 & 5789.76 & 75.6719 & 0.2MKCl & R1 \\\\\n",
       "\t7 & 7.74126 & 0.02048 & 2301.86 & 47.1469 & 0.2MKCl & R1 \\\\\n",
       "\t8 & 7.34235 & 0.0205986 & 1544.66 & 31.8211 & 0.2MKCl & R1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m8×6 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m λ_mean  \u001b[0m\u001b[1m λ_std     \u001b[0m\u001b[1m bc_mean   \u001b[0m\u001b[1m bc_std  \u001b[0m\u001b[1m env     \u001b[0m\u001b[1m rep    \u001b[0m\n",
       "     │\u001b[90m Float64 \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String  \u001b[0m\u001b[90m String \u001b[0m\n",
       "─────┼─────────────────────────────────────────────────────────\n",
       "   1 │ 8.73987  0.0110089  6247.43    68.7797  0.2MKCl  R1\n",
       "   2 │ 7.75991  0.0219595  2345.25    51.5066  0.2MKCl  R1\n",
       "   3 │ 7.37042  0.0254693  1588.81    40.4725  0.2MKCl  R1\n",
       "   4 │ 4.59857  0.107446     99.9174  10.7668  0.2MKCl  R1\n",
       "   5 │ 4.92564  0.0779711   138.196   10.7917  0.2MKCl  R1\n",
       "   6 │ 8.66376  0.0130694  5789.76    75.6719  0.2MKCl  R1\n",
       "   7 │ 7.74126  0.02048    2301.86    47.1469  0.2MKCl  R1\n",
       "   8 │ 7.34235  0.0205986  1544.66    31.8211  0.2MKCl  R1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize dataframe to save distribution parameters\n",
    "df_freq = DF.DataFrame()\n",
    "\n",
    "# Loop through files\n",
    "for f in files\n",
    "    # Split file name\n",
    "    f_split = split(split(f, \"/\")[end], \"_\")\n",
    "\n",
    "    # Extract file metadata\n",
    "    env = replace(f_split[2], \"env\" => \"\")\n",
    "    rep = replace(f_split[3], \"rep\" => \"\")\n",
    "\n",
    "    # Load chain into memory\n",
    "    chn = JLD2.load(f)[\"chain\"]\n",
    "\n",
    "    # Select variables for population mean fitness and associated variance\n",
    "    var_name = MCMCChains.namesingroup(chn, :Λ̲̲)\n",
    "\n",
    "    # Fit normal distributions to population mean fitness\n",
    "    bc_freq = Distributions.fit.(\n",
    "        Ref(Distributions.LogNormal), [vec(chn[x]) for x in var_name]\n",
    "    )\n",
    "\n",
    "    # Extract distribution parameters into matrix\n",
    "    df_param = DF.DataFrame(\n",
    "        hcat(\n",
    "            first.(Distributions.params.(bc_freq)),\n",
    "            last.(Distributions.params.(bc_freq)),\n",
    "            StatsBase.mean.(bc_freq),\n",
    "            StatsBase.std.(bc_freq),\n",
    "        ),\n",
    "        [\"λ_mean\", \"λ_std\", \"bc_mean\", \"bc_std\"]\n",
    "    )\n",
    "\n",
    "    # Add columns for time and metadata\n",
    "    DF.insertcols!(\n",
    "        df_param,\n",
    "        :env .=> env,\n",
    "        :rep .=> rep,\n",
    "    )\n",
    "\n",
    "    # Append to dataframe\n",
    "    DF.append!(df_freq, df_param)\n",
    "end # for\n",
    "\n",
    "# Write dataframe into CSV file\n",
    "CSV.write(\"$(out_dir)/bc_freq_priors.csv\", df_freq)\n",
    "\n",
    "first(df_freq, 8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and inferences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\n",
    "    \"$(git_root())/data/kinsler_2020/tidy_counts_no_anc.csv\", DF.DataFrame\n",
    ")\n",
    "\n",
    "first(data, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's list the `.jld2` files containing the MCMC chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files\n",
    "chn_files = Glob.glob(\n",
    "    \"$(git_root())/code/processing/mcmc_kinsler_fitness/output/\"[2:end] *\n",
    "    \"kinsler*jld2\",\n",
    "    \"/\"\n",
    ")\n",
    "\n",
    "println(\"# files = $(length(chn_files))\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us begin exploring one of these files to later generalize the analysis\n",
    "pipeline. Each `.jld2` file contains two objects:\n",
    "- `chain`: The `MCMCChains.Chain` object with all the samples.\n",
    "- `group`: An array listing the identity of each of the mutants in the order\n",
    "  they follow in the chain.\n",
    "\n",
    "Let's load the chain and rename the variables to the barcode names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load chain and group object form .jld2 file\n",
    "chn, group = values(JLD2.load(chn_files[1]))\n",
    "\n",
    "# Search for variable names\n",
    "s_names = MCMCChains.namesingroup(chn, \"s̲⁽ᵐ⁾\")\n",
    "# Search for variable names\n",
    "σ_names = MCMCChains.namesingroup(chn, \"σ̲⁽ᵐ⁾\")\n",
    "\n",
    "# Rename variables\n",
    "chn = MCMCChains.replacenames(\n",
    "    chn,\n",
    "    Dict(\n",
    "        zip(\n",
    "            [s_names; σ_names],\n",
    "            [[\"s[$(x)]\" for x in group]; [\"σ[$(x)]\" for x in group]]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring inferred distributions symmetry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to summarize the results is to fit a parametric distribution to\n",
    "the MCMC samples. Ideally, we can use a simple symmetric distribution such as a\n",
    "Gaussian. A necessary requirement for this is that the skewness of the MCMC\n",
    "chains should be very close to zero as\n",
    "\n",
    "Let us compute the skewness and kurtosis for all the chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable fitness variable names\n",
    "var_names = MCMCChains.namesingroup(chn, \"s\")\n",
    "\n",
    "# Convert chain to tidy dataframe\n",
    "df = DF.stack(DF.DataFrame(chn[var_names]), DF.Not([:iteration, :chain]))\n",
    "\n",
    "# Compute skewness and kurtosis\n",
    "df_summary = DF.combine(\n",
    "    DF.groupby(df, :variable),\n",
    "    :value => StatsBase.median,\n",
    "    :value => StatsBase.mean,\n",
    "    :value => StatsBase.std,\n",
    "    :value => StatsBase.var,\n",
    "    :value => StatsBase.skewness,\n",
    "    :value => StatsBase.kurtosis\n",
    ")\n",
    "\n",
    "first(df_summary, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the distribution of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = Figure(resolution=(300 * 2, 300 * 2))\n",
    "\n",
    "# Add axis\n",
    "axes = [\n",
    "    Axis(\n",
    "        fig[i, j],\n",
    "        ylabel=\"ECDF\"\n",
    "    ) for i = 1:2 for j = 1:2\n",
    "]\n",
    "\n",
    "# List quantities to plot\n",
    "qs = [\"mean\", \"var\", \"skewness\", \"kurtosis\"]\n",
    "\n",
    "# Loop through quantities\n",
    "for (i, q) in enumerate(qs)\n",
    "    # Plot quantity\n",
    "    ecdfplot!(axes[i], df_summary[:, \"value_\"*q])\n",
    "    # Add title\n",
    "    axes[i].xlabel = \"fitness $(q)\"\n",
    "end # for\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focusing in particular on the skewness⸺which we expect to be zero for a\n",
    "symmetric distribution⸺the vast majority of the density concentrates around\n",
    "zero, but there are some extreme values. Let's look at a couple of distributions\n",
    "with extreme skewness values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify minimum and maximum value of skewness\n",
    "min_skew, max_skew = [\n",
    "    df_summary[argmin(df_summary.value_skewness), :variable]\n",
    "    df_summary[argmax(df_summary.value_skewness), :variable]\n",
    "]\n",
    "\n",
    "# Initialize plot\n",
    "fig = Figure(resolution=(300 * 2, 300))\n",
    "\n",
    "# Add axis\n",
    "axes = [\n",
    "    Axis(\n",
    "        fig[1, i],\n",
    "        xlabel=\"fitness\",\n",
    "        ylabel=\"density\"\n",
    "    ) for i = 1:2\n",
    "]\n",
    "\n",
    "# Define plot titles \n",
    "titles = [\"min skewness\", \"max skewness\"]\n",
    "\n",
    "# loop through barcodes\n",
    "for (i, bc) in enumerate([min_skew, max_skew])\n",
    "    # plot density for fitness value\n",
    "    density!(axes[i], df[df.variable.==bc, :value])\n",
    "    # Add title\n",
    "    axes[i].title = titles[i]\n",
    "end # for\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even the distributions with extreme skewness values are fairly\n",
    "symmetric. The high skewness must come from the few outliers in the samples.\n",
    "Let's repeat the same plot, this time only including the 95% highest density\n",
    "percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify minimum and maximum value of skewness\n",
    "min_skew, max_skew = [\n",
    "    df_summary[argmin(df_summary.value_skewness), :variable]\n",
    "    df_summary[argmax(df_summary.value_skewness), :variable]\n",
    "]\n",
    "\n",
    "# Initialize plot\n",
    "fig = Figure(resolution=(300 * 2, 300))\n",
    "\n",
    "# Add axis\n",
    "axes = [\n",
    "    Axis(\n",
    "        fig[1, i],\n",
    "        xlabel=\"fitness\",\n",
    "        ylabel=\"density\"\n",
    "    ) for i = 1:2\n",
    "]\n",
    "\n",
    "# Define plot titles \n",
    "titles = [\"min skewness\", \"max skewness\"]\n",
    "\n",
    "# loop through barcodes\n",
    "for (i, bc) in enumerate([min_skew, max_skew])\n",
    "    # Extract values\n",
    "    skew = df[df.variable.==bc, :value]\n",
    "    # Keep only selected percentile\n",
    "    skew = skew[\n",
    "        (skew.≥StatsBase.percentile(skew, 2.5)).&(skew.≤StatsBase.percentile(skew, 97.5))\n",
    "    ]\n",
    "    # plot density for fitness value\n",
    "    density!(axes[i], skew)\n",
    "    # Add title\n",
    "    axes[i].title = titles[i]\n",
    "end # for\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the extreme values does return a reasonably symmetric distribution.\n",
    "Let's compute the summary statistics only using the 95% percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by barcode\n",
    "df_group = DF.groupby(df, :variable)\n",
    "\n",
    "# Initialize dataframe to save summaries\n",
    "df_filt = DF.DataFrame()\n",
    "\n",
    "# Loop through groups\n",
    "for g in df_group\n",
    "    # Filter data\n",
    "    DF.append!(\n",
    "        df_filt,\n",
    "        g[(g.value.≥StatsBase.percentile(g.value, 5)).&(g.value.≤StatsBase.percentile(g.value, 95)),\n",
    "            :]\n",
    "    )\n",
    "end # group\n",
    "\n",
    "# Compute skewness and kurtosis\n",
    "df_filt_summary = DF.combine(\n",
    "    DF.groupby(df_filt, :variable),\n",
    "    :value => StatsBase.median,\n",
    "    :value => StatsBase.mean,\n",
    "    :value => StatsBase.std,\n",
    "    :value => StatsBase.var,\n",
    "    :value => StatsBase.skewness,\n",
    "    :value => StatsBase.kurtosis\n",
    ")\n",
    "\n",
    "first(df_filt_summary, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, Let's plot the distribution of these summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = Figure(resolution=(300 * 2, 300 * 2))\n",
    "\n",
    "# Add axis\n",
    "axes = [\n",
    "    Axis(\n",
    "        fig[i, j],\n",
    "        ylabel=\"ECDF\"\n",
    "    ) for i = 1:2 for j = 1:2\n",
    "]\n",
    "\n",
    "# List quantities to plot\n",
    "qs = [\"mean\", \"var\", \"skewness\", \"kurtosis\"]\n",
    "\n",
    "# Loop through quantities\n",
    "for (i, q) in enumerate(qs)\n",
    "    # Plot quantity\n",
    "    ecdfplot!(axes[i], df_filt_summary[:, \"value_\"*q])\n",
    "    # Add title\n",
    "    axes[i].xlabel = \"fitness $(q)\"\n",
    "end # for\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focusing again on the skewness, we still find some values that deviate from the\n",
    "expected zero-value for symmetric distributions. Let's plot the probability\n",
    "density for the fitness value of these extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify minimum and maximum value of skewness\n",
    "min_skew, max_skew = [\n",
    "    df_filt_summary[argmin(df_filt_summary.value_skewness), :variable]\n",
    "    df_filt_summary[argmax(df_filt_summary.value_skewness), :variable]\n",
    "]\n",
    "\n",
    "# Initialize plot\n",
    "fig = Figure(resolution=(300 * 2, 300))\n",
    "\n",
    "# Add axis\n",
    "axes = [\n",
    "    Axis(\n",
    "        fig[1, i],\n",
    "        xlabel=\"fitness\",\n",
    "        ylabel=\"density\"\n",
    "    ) for i = 1:2\n",
    "]\n",
    "\n",
    "# Define plot titles \n",
    "titles = [\"min skewness\", \"max skewness\"]\n",
    "\n",
    "# loop through barcodes\n",
    "for (i, bc) in enumerate([min_skew, max_skew])\n",
    "    # plot density for fitness value\n",
    "    density!(axes[i], df_filt[df_filt.variable.==bc, :value])\n",
    "    # Add title\n",
    "    axes[i].title = titles[i]\n",
    "end # for\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are indeed not symmetric. But notice the range of the density plots; these\n",
    "extreme skewness values com from poorly identified fitness values. The\n",
    "distribution of variance values above reveals a set of identified and poorly\n",
    "identified fitness values. Let's plot this distribution to emphasize the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = Figure(resolution=(350, 350))\n",
    "\n",
    "# Add axis\n",
    "ax = Axis(\n",
    "    fig[1, 1],\n",
    "    xlabel=\"fitness variance\",\n",
    "    ylabel=\"density\",\n",
    ")\n",
    "\n",
    "# Plot density\n",
    "density!(ax, df_filt_summary[:, :value_var])\n",
    "\n",
    "# Set x-axis range\n",
    "xlims!(ax, [-0.05, 0.4])\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the barcode inferences have a variance $\\leq$ to 0.1. Let us filter out\n",
    "everything above this value and look at the skewness distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = Figure(resolution=(350, 350))\n",
    "\n",
    "# Add axis\n",
    "ax = Axis(\n",
    "    fig[1, 1],\n",
    "    xlabel=\"fitness skewness\",\n",
    "    ylabel=\"density\",\n",
    "    title=\"var ≤ 0.1\"\n",
    ")\n",
    "\n",
    "# Plot density\n",
    "ecdfplot!(\n",
    "    ax, df_filt_summary[df_filt_summary.value_var.≤0.1, :value_skewness]\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, removing the high-variance estimates reduces the range of skewness\n",
    "values. Let's look at the extreme distributions for these further-filtered\n",
    "barcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter barcodes by variance\n",
    "df_filt_summary_var = df_filt_summary[df_filt_summary.value_var.≤0.1, :]\n",
    "\n",
    "# Identify minimum and maximum value of skewness\n",
    "min_skew, max_skew = [\n",
    "    df_filt_summary_var[argmin(df_filt_summary_var.value_skewness), :variable]\n",
    "    df_filt_summary_var[argmax(df_filt_summary_var.value_skewness), :variable]\n",
    "]\n",
    "\n",
    "# Initialize plot\n",
    "fig = Figure(resolution=(300 * 2, 300))\n",
    "\n",
    "# Add axis\n",
    "axes = [\n",
    "    Axis(\n",
    "        fig[1, i],\n",
    "        xlabel=\"fitness\",\n",
    "        ylabel=\"density\"\n",
    "    ) for i = 1:2\n",
    "]\n",
    "\n",
    "# Define plot titles \n",
    "titles = [\"min skewness\", \"max skewness\"]\n",
    "\n",
    "# loop through barcodes\n",
    "for (i, bc) in enumerate([min_skew, max_skew])\n",
    "    # plot density for fitness value\n",
    "    density!(axes[i], df_filt[df_filt.variable.==bc, :value])\n",
    "    # Add title\n",
    "    axes[i].title = titles[i]\n",
    "end # for\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions are indeed fairly symmetric when filtering out the\n",
    "high-variance inferences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systematic fitting of Gaussian distributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does this analysis leave us? What we can safely conclude is that for the\n",
    "vast majority of the barcodes, fitting a parametric Gaussian curve to the MCMC\n",
    "chains is a good-enough approximation. This does not generalize to all cases,\n",
    "but we might consider discarding the cases that fail anyways because they tend\n",
    "to be poorly-determined fitness values.\n",
    "\n",
    "Let's then systematically summarize all MCMC chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataframe to save fit values\n",
    "df_fit = DF.DataFrame()\n",
    "\n",
    "# Define percentiles to include\n",
    "per = [2.5, 97.5, 16, 84]\n",
    "\n",
    "# Loop through files\n",
    "for f in chn_files\n",
    "    ## EXTRACT METADATA ##\n",
    "    # Split filename to extract metadata\n",
    "    meta_str = split(split(f, \"/\")[end], \"_\")\n",
    "    # Extract metadata\n",
    "    env = replace(meta_str[2], \"env\" => \"\")\n",
    "    rep = replace(meta_str[3], \"rep\" => \"\")\n",
    "    rmT0 = parse(Bool, replace(meta_str[4], \"rmT0.jld2\" => \"\"))\n",
    "\n",
    "    ## LOAD AND FORMAT CHAIN ##\n",
    "    # Load chain and group object form .jld2 file\n",
    "    chn, group = values(JLD2.load(f))\n",
    "\n",
    "    # Search for variable names\n",
    "    s_names = MCMCChains.namesingroup(chn, \"s̲⁽ᵐ⁾\")\n",
    "\n",
    "    # Rename variables\n",
    "    chn = MCMCChains.replacenames(\n",
    "        chn, Dict(zip(s_names, [\"s[$(x)]\" for x in group]))\n",
    "    )\n",
    "\n",
    "    ## CONVERT TO TIDY DATAFRAME ##\n",
    "    # Define variable fitness variable names\n",
    "    var_names = MCMCChains.namesingroup(chn, \"s\")\n",
    "\n",
    "    # Convert chain to tidy dataframe\n",
    "    df = DF.stack(DF.DataFrame(chn[var_names]), DF.Not([:iteration, :chain]))\n",
    "\n",
    "    ## FILTER 95% ##\n",
    "\n",
    "    # Group data by barcode\n",
    "    df_group = DF.groupby(df, :variable)\n",
    "\n",
    "    # Initialize dataframe to save summaries\n",
    "    df_filt = DF.DataFrame()\n",
    "\n",
    "    # Loop through groups\n",
    "    for g in df_group\n",
    "        # Filter data\n",
    "        DF.append!(\n",
    "            df_filt,\n",
    "            g[(g.value.≥StatsBase.percentile(g.value, 5)).&(g.value.≤StatsBase.percentile(g.value, 95)),\n",
    "                :]\n",
    "        )\n",
    "    end # group\n",
    "\n",
    "    # Compute summary statistics\n",
    "    df_summary = DF.combine(\n",
    "        DF.groupby(df_filt, :variable),\n",
    "        :value => StatsBase.median,\n",
    "        :value => StatsBase.mean,\n",
    "        :value => StatsBase.std,\n",
    "        :value => StatsBase.var,\n",
    "        :value => StatsBase.skewness,\n",
    "        :value => StatsBase.kurtosis,\n",
    "    )\n",
    "\n",
    "    # Loop through percentiles\n",
    "    for p in per\n",
    "        # Compute and add percentile\n",
    "        DF.leftjoin!(\n",
    "            df_summary,\n",
    "            # Rename column from :value_function to :p_percentile\n",
    "            DF.rename!(\n",
    "                # Compute percentile p for each group\n",
    "                DF.combine(\n",
    "                    # Group MCMC chains by :variable, :value\n",
    "                    DF.groupby(df_filt[:, [:variable, :value]], :variable),\n",
    "                    # Define anonymous function to compute percentile\n",
    "                    :value => x -> StatsBase.percentile(x, p)\n",
    "                ),\n",
    "                :value_function => Symbol(\"$(p)_percentile\")\n",
    "            );\n",
    "            on=:variable\n",
    "        )\n",
    "    end # for\n",
    "\n",
    "\n",
    "    # Add inference metadata\n",
    "    DF.insertcols!(\n",
    "        df_summary,\n",
    "        :env .=> env,\n",
    "        :rep .=> rep,\n",
    "        :rmT0 .=> rmT0\n",
    "    )\n",
    "\n",
    "    # Append to dataframe\n",
    "    DF.append!(df_fit, df_summary)\n",
    "end # for\n",
    "\n",
    "# Rename columns\n",
    "DF.rename!(\n",
    "    df_fit,\n",
    "    :variable => :barcode,\n",
    "    :value_median => :median,\n",
    "    :value_mean => :mean,\n",
    "    :value_std => :std,\n",
    "    :value_var => :var,\n",
    "    :value_skewness => :skewness,\n",
    "    :value_kurtosis => :excess_kurtosis,\n",
    ")\n",
    "\n",
    "# Replace barcode name from \"s[x]\" to x\n",
    "df_fit.barcode .= parse.(Int64, replace.(df_fit.barcode, \"s[\" => \"\", \"]\" => \"\"))\n",
    "\n",
    "# Extract barcode metadata to be added\n",
    "df_bc_meta = unique(data[:, [:barcode, :class, :gene, :ploidy, :type]])\n",
    "# Add barcode metadata\n",
    "DF.leftjoin!(df_fit, df_bc_meta; on=:barcode)\n",
    "\n",
    "# Write dataframe to CSV file\n",
    "CSV.write(\"$(git_root())/data/kinsler_2020/fitness_gaussian_fit.csv\", df_fit)\n",
    "\n",
    "first(df_fit, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring summary statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the correlation between a few of the variables.\n",
    "\n",
    "For example, we expect the mean and the median to be almost mirror-images of\n",
    "each other. Let's plot one against the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize figure\n",
    "fig = Figure(resolution=(300, 300))\n",
    "\n",
    "# Add axis\n",
    "ax = Axis(fig[1, 1], xlabel=\"fitness mean\", ylabel=\"fitness median\")\n",
    "\n",
    "# Plot mean vs median\n",
    "scatter!(ax, df_fit.mean, df_fit.median, markersize=5)\n",
    "\n",
    "# Plot identity line\n",
    "lines!(ax, [-4, 4], [-4, 4], color=:black)\n",
    "\n",
    "# Seet axis limits\n",
    "xlims!(ax, [-3, 2])\n",
    "ylims!(ax, [-3, 2])\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are as correlated as I expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = Figure(resolution=(300 * 2, 300 * 2))\n",
    "\n",
    "# Add axis\n",
    "axes = [\n",
    "    Axis(\n",
    "        fig[i, j],\n",
    "        ylabel=\"ECDF\"\n",
    "    ) for i = 1:2 for j = 1:2\n",
    "]\n",
    "\n",
    "# List quantities to plot\n",
    "qs = [\"mean\", \"var\", \"skewness\", \"excess_kurtosis\"]\n",
    "\n",
    "# Loop through quantities\n",
    "for (i, q) in enumerate(qs)\n",
    "    # Plot quantity\n",
    "    ecdfplot!(axes[i], df_fit[:, q])\n",
    "    # Add title\n",
    "    axes[i].xlabel = \"fitness $(q)\"\n",
    "end # for\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize figure\n",
    "fig = Figure(resolution=(300, 300))\n",
    "\n",
    "# Add axis\n",
    "ax = Axis(fig[1, 1], xlabel=\"fitness var\", ylabel=\"fitness skewness\")\n",
    "\n",
    "# Plot mean vs median\n",
    "scatter!(ax, df_fit.var, df_fit.skewness, markersize=5)\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate-to-replicate variability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the replicate-to-replicate variability. First, let's plot \n",
    "the pairwise comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by environment\n",
    "df_group = DF.groupby(df_fit, :env)\n",
    "\n",
    "# Find environments with two repeats\n",
    "reps = [length(unique(g.rep)) for g in df_group] .≥ 2\n",
    "\n",
    "# Keep groups with two repeats\n",
    "df_group = df_group[reps]\n",
    "\n",
    "# Define number of rows and columns\n",
    "n_row, n_col = [4, 3]\n",
    "\n",
    "# Initialize figure\n",
    "fig = Figure(resolution=(350 * n_col, 350 * n_row))\n",
    "\n",
    "# Add GridLayout\n",
    "gl = fig[1, 1] = GridLayout()\n",
    "\n",
    "# Add axis\n",
    "axes = [\n",
    "    Axis(\n",
    "        gl[i, j],\n",
    "        xlabel=\"replicate 1 median fitness\",\n",
    "        ylabel=\"replicate 2 median fitness\",\n",
    "    ) for i = 1:n_row for j = 1:n_col\n",
    "]\n",
    "\n",
    "# Loop through groups\n",
    "for (i, data) in enumerate(df_group)\n",
    "    # Unstack dataframe to plot columns\n",
    "    d = DF.unstack(data[:, [:barcode, :rep, :median]], :rep, :median)\n",
    "\n",
    "    # Plot Rep 1 vs Rep 2\n",
    "    if first(data.env) == \"M3\"\n",
    "        # Extract repeats to be used for M3\n",
    "        m3 = [d.R6, d.R7]\n",
    "        # Plot R1 vs R2\n",
    "        scatter!(axes[i], m3..., markersize=5)\n",
    "        # Plot identity line\n",
    "        lines!(\n",
    "            axes[i],\n",
    "            repeat([[minimum(vcat(m3...)), maximum(vcat(m3...))]], 2)...;\n",
    "            color=:black\n",
    "        )\n",
    "    else\n",
    "        # Plot R1 vs R2\n",
    "        scatter!(axes[i], d.R1, d.R2, markersize=5)\n",
    "        # Plot identity line\n",
    "        lines!(\n",
    "            axes[i],\n",
    "            repeat([[minimum(data.median), maximum(data.median)]], 2)...;\n",
    "            color=:black\n",
    "        )\n",
    "    end # if\n",
    "\n",
    "    # Add title\n",
    "    axes[i].title = first(data.env)\n",
    "\n",
    "end # for\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add errorbars to this plot. The error bars will represent the 68\n",
    "percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by environment\n",
    "df_group = DF.groupby(df_fit, :env)\n",
    "\n",
    "# Find environments with two repeats\n",
    "reps = [length(unique(g.rep)) for g in df_group] .≥ 2\n",
    "\n",
    "# Keep groups with two repeats\n",
    "df_group = df_group[reps]\n",
    "\n",
    "# Define number of rows and columns\n",
    "n_row, n_col = [4, 3]\n",
    "\n",
    "# Initialize figure\n",
    "fig = Figure(resolution=(350 * n_col, 350 * n_row))\n",
    "\n",
    "# Add GridLayout\n",
    "gl = fig[1, 1] = GridLayout()\n",
    "\n",
    "# Add axis\n",
    "axes = [\n",
    "    Axis(\n",
    "        gl[i, j],\n",
    "        xlabel=\"replicate 1 fitness\",\n",
    "        ylabel=\"replicate 2 fitness\",\n",
    "    ) for i = 1:n_row for j = 1:n_col\n",
    "]\n",
    "\n",
    "# Loop through groups\n",
    "for (i, data) in enumerate(df_group)\n",
    "    # Unstack dataframe to plot columns (median)\n",
    "    d = DF.sort(\n",
    "        DF.unstack(data[:, [:barcode, :rep, :median]], :rep, :median),\n",
    "        [:barcode]\n",
    "    )\n",
    "\n",
    "    # Unstack dataframe to plot columns (16 percentile)\n",
    "    d_low = DF.sort(\n",
    "        DF.unstack(\n",
    "            data[:, [:barcode, :rep, Symbol(\"16.0_percentile\")]],\n",
    "            :rep,\n",
    "            Symbol(\"16.0_percentile\")\n",
    "        ),\n",
    "        [:barcode]\n",
    "    )\n",
    "    # Unstack dataframe to plot columns (84 percentile)\n",
    "    d_high = DF.sort(\n",
    "        DF.unstack(\n",
    "            data[:, [:barcode, :rep, Symbol(\"84.0_percentile\")]],\n",
    "            :rep,\n",
    "            Symbol(\"84.0_percentile\")\n",
    "        ),\n",
    "        [:barcode]\n",
    "    )\n",
    "\n",
    "\n",
    "    # Plot Rep 1 vs Rep 2\n",
    "    if first(data.env) == \"M3\"\n",
    "        # Extract repeats to be used for M3\n",
    "        m3 = [d.R6, d.R7]\n",
    "        m3_low = [d_low.R6, d_low.R7]\n",
    "        m3_high = [d_high.R6, d_high.R7]\n",
    "        # Add y-axis error bars\n",
    "        errorbars!(\n",
    "            axes[i],\n",
    "            m3[1],\n",
    "            m3[2],\n",
    "            abs.(m3[1] .- m3_low[1]),\n",
    "            abs.(m3[1] .- m3_high[1]),\n",
    "            color=(:gray, 0.5)\n",
    "        )\n",
    "\n",
    "        # Add x-axis error bars\n",
    "        errorbars!(\n",
    "            axes[i],\n",
    "            m3[1],\n",
    "            m3[2],\n",
    "            abs.(m3[2] .- m3_low[2]),\n",
    "            abs.(m3[2] .- m3_high[2]),\n",
    "            color=(:gray, 0.5),\n",
    "            direction=:x\n",
    "        )\n",
    "        # Plot R1 vs R2\n",
    "        scatter!(axes[i], m3..., markersize=5)\n",
    "        # Plot identity line\n",
    "        lines!(\n",
    "            axes[i],\n",
    "            repeat([[minimum(vcat(m3...)), maximum(vcat(m3...))]], 2)...;\n",
    "            color=:black\n",
    "        )\n",
    "    else\n",
    "        # Add y-axis error bars\n",
    "        errorbars!(\n",
    "            axes[i],\n",
    "            d.R1,\n",
    "            d.R2,\n",
    "            abs.(d.R1 .- d_low.R1),\n",
    "            abs.(d.R1 .- d_high.R1),\n",
    "            color=(:gray, 0.5)\n",
    "        )\n",
    "\n",
    "        # Add x-axis error bars\n",
    "        errorbars!(\n",
    "            axes[i],\n",
    "            d.R1,\n",
    "            d.R2,\n",
    "            abs.(d.R2 .- d_low.R2),\n",
    "            abs.(d.R2 .- d_high.R2),\n",
    "            color=(:gray, 0.5),\n",
    "            direction=:x\n",
    "        )\n",
    "\n",
    "        # Plot R1 vs R2\n",
    "        scatter!(axes[i], d.R1, d.R2, markersize=5)\n",
    "\n",
    "        # Plot identity line\n",
    "        lines!(\n",
    "            axes[i],\n",
    "            repeat([[minimum(data.median), maximum(data.median)]], 2)...;\n",
    "            color=:black\n",
    "        )\n",
    "    end # if\n",
    "\n",
    "    # Add title\n",
    "    axes[i].title = first(data.env)\n",
    "\n",
    "end # for\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with previous inference method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important comparison to be made is with the previous inference method. Let's\n",
    "load the previous fitness measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous-method fitness inferences\n",
    "df_prev = CSV.read(\n",
    "    \"$(git_root())/data/kinsler_2020/tidy_fitness_mle.csv\", DF.DataFrame\n",
    ")\n",
    "\n",
    "# Initialize array where to save rep number. NOTE: This is done to split the \n",
    "# `EC Batch #`\n",
    "rep = ones(Int64, size(df_prev, 1))\n",
    "\n",
    "# Extract unique `EC Batch #` environments\n",
    "ec_env = unique(df_prev.environment[occursin.(\"EC Batch\", df_prev.environment)])\n",
    "\n",
    "# Loop through EC envs\n",
    "for env in ec_env\n",
    "    # Extract and save replicate number\n",
    "    rep[df_prev.environment.==env] .= parse(Int64, split(env, \" \")[end])\n",
    "    # Modify environment to be `EC Batch` only\n",
    "    df_prev[df_prev.environment.==env, :environment] .= \"EC Batch\"\n",
    "end # for\n",
    "\n",
    "# Add rep column\n",
    "df_prev[!, :rep] = [\"R$(r)\" for r in rep]\n",
    "\n",
    "first(df_prev[:, DF.Not(:additional_muts)], 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe uses a different naming convention for the environments. The file\n",
    "`env_equivalence.csv` is a manually-curated mapping between (most) environment\n",
    "names. Let's map these names to the new environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read environment naming convention\n",
    "df_env = CSV.read(\n",
    "    \"$(git_root())/data/kinsler_2020/env_equivalence.csv\", DF.DataFrame\n",
    ")\n",
    "\n",
    "# Drop environemnts that have a missing entry\n",
    "DF.dropmissing!(df_env)\n",
    "\n",
    "# Initialize array to save new environment name\n",
    "# envs = Array{Union{String,Missing}}(missing, size(df_prev, 1))\n",
    "envs = repeat([\"None\"], size(df_prev, 1))\n",
    "\n",
    "# Loop through old environments\n",
    "for row in eachrow(df_env)\n",
    "    # Add corresponding environment\n",
    "    envs[df_prev.environment.==row.old] .= row.new\n",
    "end # for\n",
    "\n",
    "# Add column to dataframe\n",
    "df_prev[!, :env] = envs\n",
    "\n",
    "first(df_prev[:, DF.Not(:additional_muts)], 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the comparison, we must find the environment/replicate pairs that appear\n",
    "in both datasets as well as the common barcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect groups for previous inference\n",
    "keys_prev = values.(keys(DF.groupby(df_prev, [:env, :rep])))\n",
    "\n",
    "# Collect groups for new inference \n",
    "keys_fit = values.(keys(DF.groupby(df_fit, [:env, :rep])))\n",
    "\n",
    "# Find intersecting groups\n",
    "keys_intersect = intersect(keys_prev, keys_fit)\n",
    "\n",
    "# Find intersecting barcodes\n",
    "bc_intersect = intersect(unique(df_fit.barcode), unique(df_prev.barcode))\n",
    "\n",
    "println(\"# envs = $(length(keys_intersect))\")\n",
    "println(\"# barcodes = $(length(bc_intersect)) out of $(length(unique(df_fit.barcode)))\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a little over 100 barcodes were excluded from the original Kinsler\n",
    "et al dataset. The authors did not explain why this is the case, so I'll need to\n",
    "ask them directly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot the pairwise comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define number of rows and columns in subplots\n",
    "n_col, n_row = [4, 5]\n",
    "\n",
    "# Initialize figure\n",
    "fig = Figure(resolution=(350 * n_col, 350 * n_row))\n",
    "\n",
    "# Add GridLayout\n",
    "gl = fig[1, 1] = GridLayout()\n",
    "\n",
    "# Add axis\n",
    "axes = [\n",
    "    Axis(\n",
    "        gl[i, j],\n",
    "        xlabel=\"Bayesian inference\",\n",
    "        ylabel=\"old method\",\n",
    "    ) for i = 1:n_row for j = 1:n_col\n",
    "]\n",
    "\n",
    "# Loop through groups\n",
    "for (i, (env, rep)) in enumerate(keys_intersect)\n",
    "    # Extract old and new inference\n",
    "    data_bayes = DF.sort!(\n",
    "        df_fit[\n",
    "            (df_fit.env.==env).&(df_fit.rep.==rep).&([x ∈ bc_intersect for x in df_fit.barcode]),\n",
    "            :],\n",
    "        :barcode\n",
    "    )\n",
    "    data_prev = DF.sort!(\n",
    "        df_prev[\n",
    "            (df_prev.env.==env).&(df_prev.rep.==rep).&([x ∈ bc_intersect for x in df_prev.barcode]),\n",
    "            :],\n",
    "        :barcode\n",
    "    )\n",
    "\n",
    "    # Plot identity line\n",
    "    lines!(\n",
    "        axes[i],\n",
    "        repeat([[\n",
    "                minimum([data_bayes.median; data_prev.fitness]),\n",
    "                maximum([data_bayes.median; data_prev.fitness])\n",
    "            ]],\n",
    "            2)...,\n",
    "        color=:black\n",
    "    )\n",
    "\n",
    "    # Plot x-axis error-bar\n",
    "    errorbars!(\n",
    "        axes[i],\n",
    "        data_bayes.median,\n",
    "        data_prev.fitness,\n",
    "        abs.(data_bayes.median .- data_bayes[:, Symbol(\"16.0_percentile\")]),\n",
    "        abs.(data_bayes.median .- data_bayes[:, Symbol(\"84.0_percentile\")]),\n",
    "        color=(:gray, 0.5),\n",
    "        direction=:x\n",
    "    )\n",
    "\n",
    "    # Plot y-axis error-bar\n",
    "    errorbars!(\n",
    "        axes[i],\n",
    "        data_bayes.median,\n",
    "        data_prev.fitness,\n",
    "        data_prev.error,\n",
    "        color=(:gray, 0.5),\n",
    "        direction=:y\n",
    "    )\n",
    "\n",
    "    # Plot centroid\n",
    "    scatter!(axes[i], data_bayes.median, data_prev.fitness, markersize=7)\n",
    "\n",
    "    # Set title\n",
    "    axes[i].title = \"$(env) | $(rep)\"\n",
    "end # for\n",
    "\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there are some suspiciously-diverging comparisons, these are mostly for\n",
    "the M3 datasets, where I am less certain about the replicate number matching\n",
    "with each other (something interesting to consider about the M3 data), the rest\n",
    "of the comparisons look really good. As expected, the error bars from the\n",
    "Bayesian inference look significantly bigger than with the older method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
