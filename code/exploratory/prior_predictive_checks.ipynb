{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) 2023 Manuel Razo. This work is licensed under a [Creative Commons\n",
    "Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).\n",
    "All code contained herein is licensed under an [MIT\n",
    "license](https://opensource.org/licenses/MIT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load project package\n",
    "@load_pkg BayesFitUtils\n",
    "\n",
    "# Import project package\n",
    "import BayesFitUtils\n",
    "\n",
    "# Import package to handle DataFrames\n",
    "import DataFrames as DF\n",
    "import CSV\n",
    "\n",
    "# Import package to load chains\n",
    "import JLD2\n",
    "\n",
    "# Import package to handle MCMC chain objects\n",
    "import MCMCChains\n",
    "\n",
    "# Import basic statistical functions\n",
    "import StatsBase\n",
    "import Distributions\n",
    "import Random\n",
    "\n",
    "# Import basic math\n",
    "import LinearAlgebra\n",
    "\n",
    "# Load CairoMakie for plotting\n",
    "using CairoMakie\n",
    "import ColorSchemes\n",
    "import Makie\n",
    "# Activate backend\n",
    "CairoMakie.activate!()\n",
    "\n",
    "# Set PBoC Plotting style\n",
    "BayesFitUtils.viz.pboc_makie!()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Based Calibration (SBC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key part of the [Principled Bayesian\n",
    "Workflow](https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html)\n",
    "comes in the form of the so-called prior predictive checks implemented as the\n",
    "Simulation-Based Calibration (SBC). In Bayesian statistics there is not\n",
    "guarantee that the posterior distribution will actually contain the \"ground\n",
    "truth\" parameter value. That is the whole point of the SBC in the first place.\n",
    "What it is guaranteed is that if one samples parameter values from the prior (as\n",
    "in the prior predictive checks), and runs the inference on this prior sample, in\n",
    "the long term, the posterior distributions one obtains should recover the prior\n",
    "distribution. The procedure looks as follows:\n",
    "\n",
    "First we sample a set of parameters from the prior\n",
    "$$\n",
    "\\tilde\\theta \\sim \\pi(\\theta),\n",
    "$$\n",
    "Then we generate data using the set of parameters and the generative model\n",
    "$$\n",
    "\\tilde{y} \\sim \\pi(y \\mid \\tilde\\theta).\n",
    "$$\n",
    "Then we run the\n",
    "inference on the parameters given the synthetic data\n",
    "$$\n",
    "\\pi(\\tilde\\theta \\mid \\tilde y) \\propto \n",
    "\\pi(\\tilde y \\mid \\tilde\\theta) \\pi(\\tilde\\theta).\n",
    "$$\n",
    "Doing this over and over and over again should at the end of the day recover the\n",
    "prior distribution. This is\n",
    "$$\n",
    "\\pi(\\theta) = \\int d\\tilde y\\; d\\tilde\\theta\\; \\pi(\\theta\n",
    "\\mid \\tilde y) \\pi(\\tilde y \\mid \\tilde\\theta)\\pi(\\tilde\\theta),\n",
    "$$\n",
    "where for this result we first used\n",
    "$$\n",
    "\\int d\\tilde\\theta\\; \\pi(\\tilde y \\mid \\tilde\\theta)\n",
    "\\pi(\\tilde\\theta) = \\int d\\tilde\\theta\\; \\pi(\\tilde y, \\tilde\\theta) =\n",
    "\\pi(\\tilde y),\n",
    "$$\n",
    "and then\n",
    "$$\n",
    "\\int d\\tilde y\\; \\pi(\\theta \\mid \\tilde y) \\pi(\\tilde y) = \n",
    "\\int d\\tilde y\\; \\pi(\\theta, \\tilde y) = \\pi(\\theta).\n",
    "$$\n",
    "In other words, for any model the average of any exact posterior expectation\n",
    "with respect to data generated from the Bayesian joint distribution reduces to\n",
    "the corresponding prior expectation.We then know that repeating the inference\n",
    "over and over again with many different ground truths should recover the prior\n",
    "distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating simulated frequency trajectories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the simulation-based calibration procedure on our fitness inferences,\n",
    "we need to generate synthetic datasets according to our model. In particular,\n",
    "our inference is of the form\n",
    "$$\n",
    "\\pi\\left(\n",
    "    \\underline{s}^{M}, \\underline{\\bar{s}}_t, \\underline{\\underline{F}} \\mid \n",
    "    \\underline{\\underline{R}}\n",
    "\\right) \\propto \n",
    "\\pi\\left(\n",
    "    \\underline{\\underline{R}} \\mid \n",
    "    \\underline{\\underline{F}}, \\underline{s}^{M}, \\underline{\\bar{s}}_t\n",
    "\\right) \n",
    "\\pi\\left(\n",
    "    \\underline{\\underline{F}}, \\underline{s}^{M}, \\underline{\\bar{s}}_t\\right\n",
    "),\n",
    "$$\n",
    "where\n",
    "- $\\underline{s}^{M}$ is a vector with the $M$ mutant barcode fitness values.\n",
    "- $\\underline{\\bar{s}}_t$ is a vector with the $T-1$ population mean fitness\n",
    "  values for every pair of time points.\n",
    "- $\\underline{\\underline{F}}$ is a $T \\times B$ matrix with the frequency\n",
    "  profiles for all $B = M + N$ barcodes.\n",
    "- $\\underline{\\underline{R}}$ is a $T \\times B$ matrix with the raw barcode\n",
    "  count profiles for all $B = M + N$ barcodes.\n",
    "\n",
    "Our model assumes that the mutant barcode frequencies evolve over time according\n",
    "to an exponential growth of the form \n",
    "$$\n",
    "f_{t+1}^{(m)} = f_{t}^{(m)} \\mathrm{e}^{(s^{(m)} - \\bar{s}_t)\\tau},\n",
    "$$\n",
    "where\n",
    "- $f_{t}^{(m)}$ is the frequency of mutant $m$ at time $t$.\n",
    "- $s^{(m)}$ is the mutant relative fitness (the $m$-th entry of\n",
    "  $\\underline{s}^{(m)}$).\n",
    "- $\\bar{s}_t$ is the population mean fitness at time $t$ (the $t$-th) entry of\n",
    "  $\\underline{s}_t$.\n",
    "- $\\tau$ is the time interval between $t$ and $t+1$.\n",
    "\n",
    "The easiest way to generate a barcode trajectory is to first generate the\n",
    "deterministic trajectories using this exponential growth function and then add\n",
    "noise on top of these trajectories."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define the number of barcodes, their corresponding fitness, and\n",
    "their initial count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(42)\n",
    "\n",
    "# Define number of neutral barcodes\n",
    "n_neutral = 10\n",
    "# Define number of mutant barcodes\n",
    "n_mutant = 90\n",
    "# Define total number of barcodes\n",
    "n_barcode = n_neutral + n_mutant\n",
    "\n",
    "# Define prior values for mutant fitness\n",
    "s_mut_prior = [0.3, 0.3]\n",
    "# Define prior values for initial λ values\n",
    "λ_prior = [3, 3]\n",
    "\n",
    "# Sample mutant fitness values\n",
    "s̲ᴹ = Random.rand(Distributions.Normal(s_mut_prior...), n_mutant)\n",
    "\n",
    "# Sample λ parameter values for all mutants\n",
    "R_init = Random.rand(Distributions.LogNormal(λ_prior...), n_barcode);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's compute the frequency dynamics over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of time points\n",
    "n_time = 5\n",
    "\n",
    "# Initialize matrix to store neutral counts and frequencies\n",
    "R̲̲ᴺ = Matrix{Float64}(undef, n_time, n_neutral)\n",
    "# Initialize matrix to store mutant frequencies\n",
    "R̲̲ᴹ = Matrix{Float64}(undef, n_time, n_mutant)\n",
    "\n",
    "# Add initial time point\n",
    "R̲̲ᴺ[1, :] = R_init[1:n_neutral]\n",
    "R̲̲ᴹ[1, :] = R_init[n_neutral+1:end]\n",
    "\n",
    "# Loop through time points\n",
    "for t = 2:n_time\n",
    "    # Integrate dynamics\n",
    "end # for"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
