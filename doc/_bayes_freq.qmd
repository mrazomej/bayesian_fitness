---
editor:
    render-on-save: true
---

### Frequency uncertainty $\pi(\underline{\underline{F}} \mid \underline{\underline{R}})$ {#sec-bayes_freq}

We begin with the probability of the frequency values given the raw barcode
reads. The first assumption is that the inference of the frequency
values for time $t$ is independent of any other time. Therefore, we can write
the joint probability distribution as a product of independent distributions of
the form
$$
\pi(\underline{\underline{F}} \mid \underline{\underline{R}}) =
\prod_{t=1}^T \pi(\underline{f}_t \mid \underline{r}_t),
$${#eq-freq_indep}
where $\underline{f}_t$ and $\underline{r}_t$ are the $t$-th row of the matrix
containing all of the measurements for time $t$. We imagine that when the 
barcode reads are obtained via sequencing, the quantified number of reads is a
Poisson sample from the "true" underlying number of barcodes within the pool. 
This translates to assuming that the number of reads for each barcode at any
time point $r^{(b)}_t$ is an independent Poisson random variable, i.e.,
$$
r^{(b)}_t \sim \text{Poiss}(\lambda^{(b)}_t),
$${#eq-freq_poisson_reads}
where the symbol "$\sim$" is read "distributed as." Furthermore, for a Poisson
distribution, we have that
$$
\lambda^{(b)}_t = \left\langle r^{(b)}_t \right\rangle = 
\left\langle 
    \left( r^{(b)}_t - \left\langle r^{(b)}_t \right\rangle \right)^2
\right\rangle,
$${#eq-freq_poisson_lambda}
where $\left\langle \cdot \right\rangle$ is the expected value. In other words
the Poisson parameter is equal to the mean and variance of the distribution. The
Poisson distribution has the convenient property that for two Poisson 
distributed random variables $X \sim \text{Poiss}(\lambda_x)$ and 
$Y \sim \text{Poiss}(\lambda_y)$, we have that
$$
Z \equiv X + Y \sim \text{Poiss}(\lambda_x + \lambda_y).
$${#eq-freq_additivity}
This additivity allows us to write the total number of reads at time $t$ $n_t$
also as a Poisson-distributed random variable of the form
$$
n_t \sim \text{Poiss}\left( \sum_{b=1}^B \lambda^{(b)}_t \right),
$${#eq-freq_poisson_total}
where the sum is taken over all $B$ barcodes.

If the total number of reads is given by @eq-freq_poisson_total, the array with
the number of reads for each barcode at time $t$, $\underline{r}_t$ is then
distributed as
$$
\underline{r}_t \sim \text{Multinomial}(n_t, \underline{f}_t),
$${#eq-freq_multinomial}
where each of the $B$ entries of the frequency vector $\underline{f}_t$ is a
function of the $\underline{\lambda}_t$ vector, given by
$$
f_t^{(b)} \equiv f_t^{(b)}(\underline{\lambda}_t) = 
\frac{\lambda_t^{(b)}}{\sum_{b'=1}^B \lambda_t^{(b')}}.
$${#eq-freq_freq_lambda}
In other words, we can think of the $B$ barcode counts as independent Poisson
samples or as a single multinomial draw with a random number of total draws,
$n_t$, and the frequency vector $\underline{f}_t$ we are interested in. Notice
that @eq-freq_freq_lambda is a deterministic function that connects the Poisson
parameters to the frequencies. Therefore, we have the equivalence that
$$
\pi(\underline{f}_t \mid \underline{r}_t) = 
\pi(\underline{\lambda}_t \mid \underline{r}_t),
$${#eq-freq_f_lambda_equiv}
meaning that the uncertainty comes from the $\underline{\lambda}_t$ vector. By
Bayes theorem, we therefore write
$$
\pi(\underline{\lambda}_t \mid n_t, \underline{r}_t) \propto
\pi(n_t, \underline{r}_t \mid \underline{\lambda}_t) \pi(\underline{\lambda}_t),
$${#eq-freq_lambda_bayes}
where we explicitly include the dependence on $n_t$. This does not affect the
distribution or brings more uncertainty because $\underline{r}_t$ already 
contains all the information to compute $n_t$ since
$$
n_t = \sum_{b=1}^B r_t^{(b)}.
$${#eq-freq_n_sum_r}
But adding the variable allows us to factorize @eq-freq_lambda_bayes as
$$
\pi(\underline{\lambda}_t \mid n_t, \underline{r}_t) \propto
\pi(n_t, \underline{r}_t \mid \underline{\lambda}_t) 
\pi(n_t \mid \underline{\lambda}_t) \pi(\underline{\lambda}_t).
$${#eq-freq_lambda_bayes_factorized}
We then have
$$
\underline{r}_t \mid n_t, \underline{\lambda}_t \sim
\text{Multinomial}(n_t, \underline{f}_t(\underline{\lambda}_t)).
$${#eq-freq_r_bayes}
Furthermore, we have
$$
n_t \mid \underline{\lambda}_t \sim 
\text{Poiss}(\sum_{b=1}^B \lambda_t^{(b)}).
$${#eq=freq_n_bayes}
Finally, for our prior $\pi(\underline{\lambda}_t)$, we first assume each 
parameter is independent, i.e.,
$$
\pi(\underline{\lambda}_t) = \prod_{b=1}^B \pi(\lambda_t^{(b)}).
$$
A reasonable prior for each $\lambda_t^{(b)}$ representing the expected number
of reads for barcode $b$ should span several orders of magnitude. Furthermore,
we assume that no barcode in the dataset ever goes extinct. Thus, no frequency
can equal zero, facilitating the computation of the log frequency ratios
needed to infer the relative fitness. The log-normal distribution satisfies 
these constraints; therefore, for the prior, we assume
$$
\lambda_t^{(b)} \sim 
\log\mathcal{N}(\mu_{\lambda_t^{(b)}}, \sigma_{\lambda_t^{(b)}}),
$$
with $\mu_{\lambda_t^{(b)}}, \sigma_{\lambda_t^{(b)}}$ as the user-defined 
parameters that characterize the prior distribution.