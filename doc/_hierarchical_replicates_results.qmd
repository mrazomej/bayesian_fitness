---
editor:
    render-on-save: true
bibliography: references.bib
csl: ieee.csl
---

## Accounting for experimental replicates via hierarchical models{#sec-replicates}

Our inference pipeline can be extended to account for multiple experimental
replicates via Bayesian hierarchical models [@betancourt2013]. Briefly, when
accounting for multiple repeated measurements of the same phenomena, there are
two extreme cases one can use to perform the data analysis: On the one hand, we
can treat each measurement as entirely independent, losing the power to utilize
multiple measurements when trying to learn a single parameter. This can hurt the
inference since, in principle, the value of our parameter of interest should not
depend on the particular experimental replicate in question. However, this
approach does not allow us to properly "combine" the uncertainties in both
experiments when performing the inference. On the other hand, we can pool all
data together and treat our different experiments as a single measurement with
higher coverage. This loses the subtle differences from biotic and abiotic batch
effects, effectively halving the data that goes into our inference problem.

Hierarchical models present a middle ground between these extremes. First,
hierarchical models rely on the definition of so-called *hyper-parameters*, that
capture the parametric inference we are interested in---for this inference
problem, we have a hyper-fitness value $\theta^{(m)}$ for each mutant. Second,
each experiment draws randomly from the distribution of this hyper-parameter,
allowing for subtle variability between experiments to be accounted for---in the
present inference pipeline, each experimental replicate gets assigned a *local*
fitness value $s^{(m)}_i$, where the extra sub-index indicates the $i$-th
experimental replicate. For our hierarchical model, these local fitness values
interact via the common dependency on the global hyper-fitness value. As
schematized in @fig-03(A), this interaction runs both ways. First, the data from
one experimental replicate ($\underline{\underline{R}}^M_k$ in the diagram)
informs all local fitness values via the global hyper-fitness (upper panel in
@fig-03(A)). Second, the local fitness value is informed by the data from all
experimental replicates via the same global hyper-fitness parameter (lower panel
in @fig-03(A)).

To test the performance of this model, we simulated two experimental replicates
with 1000 unique barcodes (see @fig-03(B-C)) where we randomly sampled a ground
truth hyper-fitness value $\theta^{(m)}$ for each barcode. We sampled a
variation from this hyper-fitness value for each experimental replicate $s^{(m,
i)}$ to capture experimental batch effects. @fig-03(D) shows the relationship
between hyper-fitness and replicate fitness values for this simulation. The
posterior predictive checks examples in @fig-03(E) show that the hierarchical
model can correctly fit the data for each experimental replicate. Furthermore,
@fig-03(F-G) show a high correlation between the ground truth and the inferred
fitness values. The ECDFs shown in @fig-03(H-I) reveal that for $\approx 75\%$
of the non-neutral barcodes, the ground truth hyper-fitness values fall within
one standard deviation from the mean value in the posterior distributions.

![**Hierarchical model on experimental replicates**. (A) Schematic depiction of
the interactions between local fitness values $\underline{s}_l^M$ through the
global hyper-fitness value $\underline{\theta}^M$ for $K$ hypothetical
experimental replicates. The upper diagram shows how the data from replicate $k$
informs all local fitness values via the hyper-fitness parameter. The lower
panel shows the reverse, where all datasets inform the local fitness value.
(B-C) Simulated replicate datasets with 900 barcodes of interest and 100 neutral
lineages. (D) Comparison between the simulation ground truth hyper-fitness and
each replicate ground truth fitness. The scatter between parameters captures
experimental batch effects. (E) Examples of the posterior predictive checks for
all neutral lineages (upper left panels) and a subset of representative mutant
lineages. Shaded regions from light to dark represent the 95\%, 68\%, and 5\%
credible regions. (F-G) Comparison between the simulation's ground truth
hyper-fitness (F) and replicate fitness (G) values and the inferred parameters.
Gray error bars represent the 68\% posterior credible region. (H-I) The
empirical cumulative distribution function (ECDF) for the absolute z-score value
of the ground truth parameter value within the inferred hyper-fitness posterior
distribution (H) and replicate fitness (I).](./figs/fig03){#fig-03}

As shown in @fig-04, the structure imposed by the hierarchical model schematized
in @fig-03(A), where we explicitly account for the connection between
experimental replicates can improve the quality of the inference. Inferred
fitness values between experimental replicates exhibit a stronger degree of
correlation in the hierarchical model (@fig-04(A)) compared to conducting
inference on each replicate independently (@fig-04(B)). Moreover, when comparing
the inferred hyper-fitness values---the objective parameter when performing
multiple experimental measurements---the hierarchical model outperforms
averaging the independent experimental replicates as shown in @fig-04(C) and
(D).

![**Comparison between hierarchical model and single dataset model**. (A-B)
comparison of inferred fitness values between experimental replicates when
fitting a hierarchical model (A) or independently fitting each dataset (B). Gray
error bars represent the 68\% credible regions. (C) Comparison between the
ground truth hyper-fitness value and the inferred parameters. The blue dots show
the inferred hyper-fitness values when assuming a hierarchical model. Gray error
bars show the 68\% credible region for this inference. The yellow dots show the
average of the mean inferred fitness values for the two experimental replicates.
No error bars are shown for these, as it is inappropriate to compute one with
two data points. (D) Empirical cumulative distribution function (ECDF) of the
absolute difference between the inferred mean and the ground truth
hyper-fitness.](./figs/fig04){#fig-04}