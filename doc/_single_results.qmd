---
editor:
    render-on-save: true
bibliography: references.bib
csl: ieee.csl
---

## Inference on a single dataset

To assess the inference pipeline performance we applied it to a simulated
dataset with known ground truth relative fitness values (See `[ref to SI]` for
details on simulation). @fig-02(A) shows the structure of the synthetic dataset.
The majority of barcodes of interest (dim color lines) are adaptive compared to
the neutral barcodes ($s^{(m)} > 0$). This experimental condition is required to
reliably measure the relative fitness since all barcodes of interest occupy a
small fraction of the population at the beginning of the experiment `[ref SI
section on detrimental mutants]`. Although the barcode frequency trajectories
look relatively smooth, our fitness model requires the computation of the log
frequency ratio between adjacent time points as derived in @eq-logfreq.
@fig-02(B) shows such data transformation where we can better appreciate the
observational noise input into our statistical model. This noise is
evident for the darker lines representing the neutral barcodes since
all of these lineages are assumed to be identically distributed under this log
frequency ratio transformation.

A way to visualize the performance of our inference pipeline in fitting our
fitness model to the observed data is to compute the so-called posterior
predictive checks (PPC). In short, the PPC consists of bootstrapping the
generation of synthetic datasets in agreement with the results from the
inference results. In other words, we use the resulting parameter values from
the ADVI inference to generate possible datasets in agreement with the inferred
values. @fig-02(C) shows these results for all neutral lineages (upper left
corner plot) and a few representative non-neutral barcodes. The dark color line
shows the median value we would expect the data to be found, while the shaded
regions show the 68\% and 95\% credible regions, i.e., the regions where we
expect to find the data with the corresponding probability---or in terms of our
parameter, the $X\%$ credible region is the interval where we expect the true
parameter to lie with $X\%$ probability. The main advantage of our method is
this natural interpretability of these credible regions since a common mistake
in the literature is to interpret frequentist confidence intervals as Bayesian
credible regions when they are not equivalent [@morey2016].

To capture the global performance of the model, @fig-02(D) compares the known
ground truth with the inferred relative fitness value for all barcodes of
interest. There is an excellent degree of correspondence between these values,
with the error bars, representing the 68\% credible region for the parameter
value crossing the identity line for most barcodes. This latter point is made
clear with @fig-02(E) where $\approx 90\%$ of ground truth fitness values fall
within one standard deviation of the mean in the inferred posterior
distributions.

![**Single dataset inference**. (A) Frequency trajectories that represent the
raw data going into the inference. (B) Log frequency ratio between two adjacent
time points used by the inference pipeline. Darker lines represent the neutral
barcodes. Notice that these transformed data are much more noisy than the
seemingly smooth frequency trajectories. (B) Examples of the posterior
predictive checks for all neutral lineages (upper left panel) and a subset of
representative mutant lineages. Error bars represent the 68\% credible region on
the mutant relative fitness marginal distribution. (C) Comparison between the
ground truth fitness value from the logistic-growth simulation and the inferred
fitness value. Gray error bars represent the 68\% posterior credible region. (D)
The empirical cumulative distribution function (ECDF) for the absolute z-score
value of the ground truth parameter value within the inferred fitness
posterior distribution.](./figs/fig02){#fig-02}