---
editor:
    render-on-save: true
bibliography: references.bib
---

## Inference on a single dataset

To assess the inference pipeline performance, we applied it to a simulated
dataset with known ground truth relative fitness values (See @sec-logistic for
details on simulation). @fig-02(A) shows the structure of the synthetic dataset.
The majority of barcodes of interest (faint color lines) are adaptive compared
to the neutral barcodes ($s^{(m)} > 0$). Although the barcode frequency
trajectories look relatively smooth, our fitness model requires the computation
of the log frequency ratio between adjacent time points as derived in
@eq-logfreq. @fig-02(B) shows such data transformation where we can better
appreciate the observational noise input into our statistical model. This noise
is evident for the darker lines representing the neutral barcodes since all of
these lineages are assumed to be identically distributed.

To visualize the performance of our inference pipeline in fitting our fitness
model to the observed data, we compute the so-called posterior predictive checks
(PPC). In short, the PPC consists of repeatedly generating synthetic datasets in
agreement with the results from the inference results. In other words, we use
the resulting parameter values from the ADVI inference to generate possible
datasets in agreement with the inferred values (See @sec-ppc for further details
on these computations). @fig-02(C) shows these results for all neutral lineages
(upper left corner plot) and a few representative non-neutral barcodes. The
different color shades represent the 95\%, 68\%, and 5\% credible regions, i.e.,
the regions where we expect to find the data with the corresponding
probability---or in terms of our parameter, the $X\%$ credible region is the
interval where we expect the true parameter value to lie with $X\%$ probability. 

The main advantage of our method is the natural interpretability of these
credible regions where an $X\%$ credible region indeed captures the region of
parameter space where we expect with $X\%$ probability the actual value of the
parameter lies given our statistical model, our prior information, and the
observed experimental data.
<span style="color: #912E27;">
Bayesian methods avoid common misconceptions associated with the construction of
frequentists confidence intervals [@morey2016].
</span> 

To capture the global performance of the model, @fig-02(D) compares the known
ground truth with the inferred relative fitness value for all barcodes of
interest. There is an excellent degree of correspondence between these values,
with the error bars representing the 68\% credible region for the parameter
value crossing the identity line for most barcodes. This latter point is made
clear with @fig-02(E) where $\approx 90\%$ of ground truth fitness values fall
within one standard deviation of the mean in the inferred posterior
distributions.

![**Single dataset inference**. (A) Frequency trajectories that represent the
raw data going into the inference. (B) Log frequency ratio between two adjacent
time points used by the inference pipeline. Darker lines represent the neutral
barcodes. These transformed data are much more noisy than the seemingly smooth
frequency trajectories. (C) Examples of the posterior predictive checks for all
neutral lineages (upper left panel) and a subset of representative mutant
lineages. Shaded regions represent the 95\%, 68\%, and 5\% credible regions for
the data. The reported errors above the plot represent the 68\% credible region
on the mutant relative fitness marginal distribution. (D) Comparison between the
ground truth fitness value from the logistic-growth simulation and the inferred
fitness value. Gray error bars represent the 68\% posterior credible region for
the relative fitness values. (E) The empirical cumulative distribution function
(ECDF) for the absolute z-score value of the ground truth parameter value within
the inferred fitness posterior distribution.](./figs/fig02){#fig-02}